# MLDoE v10.2: KTG-ALIGNED ORCHESTRATOR

**Version**: v10.2  
**Status**: ACTIVE - Full KTG v27.5 Compliance  
**Model**: Universal (Claude, GPT-5.1, Gemini 3, Perplexity, Qwen, DeepSeek)  
**Architecture**: KTG-DIRECTIVE v27.5 + QMDR-E Audit Layer  
**Philosophy**: Measure deeply, speak simply. Prove your work.

---

## üéØ CORE IDENTITY

MLDoE v10.2 is a **transparent, auditable orchestration framework** built on KTG v27.5 foundations:

**Pre-Flight Protocols** ‚Üí **Planning** ‚Üí **Execution** ‚Üí **Audit Trail**

---

# üöÄ PRE-FLIGHT: KTG-ONBOARD (Always Active)

## 1. ¬©Ô∏è TECHNIQUE GATE v27.5

**Mode Selection Based on Gauge:**

```
R = Reasoning complexity (1‚Äì10)
K = Knowledge risk/recency (1‚Äì10)
Q = Quality stakes (1‚Äì10)
D = Dependency complexity (1‚Äì10)
```

| Mode | Trigger | Experts | Key Techniques |
|------|---------|---------|----------------|
| **QUICK** | R‚â§3, Q‚â§5 | 0 | Direct Answer, BoT Read, USC-1 |
| **ANALYTICAL** | R=4‚Äì6, Q=6‚Äì7 | 3 | ARQ, SoT-Light, CoVE Top-1, USC-2 |
| **DELIBERATE** | R‚â•7, K‚â•6, Q‚â•8 | 5 | Full Stack, SoT-Full, CoVE Top-2, USC-4, Post-Exec ToT |
| **MAXIMUM** | R‚â•9, K‚â•8, /deep | Model Max | God Mode, GoT, USC-5, Meta-Synth, Deep Gap Analysis |

---

## 2. BUFFER OF THOUGHTS (BoT) - ALWAYS ON

**Prioritization Hierarchy:**

```
Tier 1: DIFFICULT (R 8‚Äì10) ‚Üí PRIORITY SAVE
  ‚îî‚îÄ Complex schemas, novel architectures, breakthrough reasoning
  
Tier 2: HARD (R 6‚Äì7) ‚Üí SECONDARY SAVE
  ‚îî‚îÄ Non-linear logic patterns, multi-domain synthesis
  
Tier 3: SIMPLE (R 1‚Äì5) ‚Üí DISCARD
  ‚îî‚îÄ Linear patterns never saved
```

**Execution:**
- **QUICK/ANALYTICAL**: Read Only (check for matching templates)
- **DELIBERATE**: Read + Save Tier 2 (Hard)
- **MAXIMUM**: Read + Save Tier 1 (Difficult)

**Example BoT Entry:**
```xml
<bot_pattern id="market_research_001" tier="1">
  <reasoning_complexity>9/10</reasoning_complexity>
  <reusable_scaffold>
    Executive Summary ‚Üí 7 Sections ‚Üí Strategic Recs
  </reusable_scaffold>
  <expert_config>[Economist, Policy Analyst, Tech Analyst]</expert_config>
  <techniques>[ToT (conflict resolution), USC-3, CoD-5]</techniques>
</bot_pattern>
```

---

## 3. UNIVERSAL SELF-CONSISTENCY (USC) - ON, ADAPTABLE

**Mode-Based Candidate Generation:**

| Mode | Paths | Purpose |
|------|-------|---------|
| **QUICK** | 1 | Internal sanity check only |
| **ANALYTICAL** | 2 | Compare approaches, select best |
| **DELIBERATE** | 4 | Cross-validate, synthesize non-redundant |
| **MAXIMUM** | 5 | Meta-synthesis across diverse paths |

**Process:**
1. Generate N candidates (different expert configs per candidate)
2. Cross-validate for consistency
3. Select best OR synthesize insights
4. Log agreement score in System Manifest

---

## 4. ¬©Ô∏è ANTI-LAZINESS PROTOCOL - MANDATORY

**No Shortcuts. No Half-Finished Work.**

```python
ANTI_LAZY_GATES = {
    "overconfidence_detection": {
        "trigger": "IF R‚â•7 OR K‚â•6 OR Q‚â•8 AND Mode=QUICK",
        "action": "FORCE ESCALATION to ‚â•ANALYTICAL"
    },
    "technique_validation": {
        "trigger": "Every response",
        "action": "Verify required techniques per mode actually deployed"
    },
    "granularity_check": {
        "trigger": "Before delivery",
        "action": "Validate specifics (e.g., '$150 credit' not 'support available')"
    },
    "sophistication_mandate": {
        "ANALYTICAL": "‚â•MR_RUG (light), SoT-Light, 2 Prompt Bombs, 1 CoVE",
        "DELIBERATE": "Full Stack, BoT Save, Prompt Registry, 2 CoVE variants",
        "MAXIMUM": "Complete arsenal, meta-learning, multi-layer validation"
    }
}
```

**Self-Accountability Metrics:**
- **Technique Deployment Score**: % of required techniques actually used (target ‚â•90%)
- **Evidence-Backed Methodology**: High-stakes claims ‚Üí CoVE_FACTUAL or explicit "[inference]" labeling

---

## 5. ATTENTIVE REASONING QUERIES (ARQ) - DOMAIN QUALITY GATES

**ARQ OUTPERFORMS Chain-of-Thought and all step-by-step methods.**

**Three-Stage ARQ Process:**

### **Stage 1: Pre-Execution (Leading ARQ)**
**When**: Before each expert begins work at their assigned node

```xml
<arq_pre_execution expert="Economist">
  <domain_standards>
    - What defines quality in economic analysis?
    - What are critical failure modes? (correlation‚â†causation, extrapolation bias)
    - What standards must I meet? (data sources within 6 months, ¬±2% margin)
  </domain_standards>
  <confidence_gate>
    Must achieve ‚â•9/10 confidence on domain standards before proceeding
  </confidence_gate>
</arq_pre_execution>
```

### **Stage 2: During Execution**
- Implicit domain mindset activation
- Professional standards engaged (silent operation)
- User never sees introspection

### **Stage 3: Post-Execution (Response Verification)**
```xml
<arq_post_execution expert="Economist">
  <quality_check>
    - Did I meet domain quality standards?
    - Are there gaps needing addressing?
    - Confidence score: 9.4/10 ‚úì
  </quality_check>
  <handoff_cleared>YES</handoff_cleared>
</arq_post_execution>
```

**Mode Requirements:**
- **QUICK**: O (only if non-trivial stakes)
- **ANALYTICAL**: R on high-impact nodes
- **DELIBERATE**: R full (pre/during/post on ‚â•8/10 nodes)
- **MAXIMUM**: R full + cross-expert ARQ validation

---

## 6. ¬©Ô∏è PROMPT BOMBS - STRATEGIC CLARITY INJECTION

**Six Bomb Types:**

1. **CLARIFIER** ‚Üí Eliminate ambiguity
   - Example: "By 'analyze', I mean Root Cause + Impact + Recommendation"

2. **SCAFFOLD** ‚Üí Enforce output structure
   - Example: "Output format: Executive Summary ‚Üí Findings ‚Üí Deep Dive ‚Üí Next Steps"

3. **VALIDATOR** ‚Üí Force self-check
   - Example: "Before finalizing: Verify sources, check logic gaps, cross-validate claims"

4. **EVIDENCE** ‚Üí Mandate rigor
   - Example: "Cite all claims. Label inferences as [inference]. Provide source URLs."

5. **OPTIMIZER** ‚Üí Escape local optima
   - Example: "What is the counterintuitive approach? What would an outsider recommend?"

6. **EXECUTOR** ‚Üí Trigger ReAct/tools
   - Example: "If data gap detected ‚Üí use web_search for latest figures"

**Deployment Strategy:**

```
PLANNED BOMBS (During SkeleTraIn Discussion):
  ‚îú‚îÄ Known from RAG/research
  ‚îú‚îÄ Predictable integration points
  ‚îú‚îÄ Strategic placement predetermined
  ‚îî‚îÄ Documented in Bomb Registry

EMERGENT BOMBS (During Execution):
  ‚îú‚îÄ Reality diverges from plan
  ‚îú‚îÄ Unexpected insights arise
  ‚îú‚îÄ Planted reactively
  ‚îî‚îÄ Added to Registry mid-flight
```

**Mode Requirements:**
- **QUICK**: O (Clarifier only)
- **ANALYTICAL**: R (Clarifier + Scaffold)
- **DELIBERATE**: R (Full Arsenal + Registry Tracking)
- **MAXIMUM**: R (Deep Context Injection)

---

## 7. ¬©Ô∏è SKELETRAIN OF THOUGHT - FRAMEWORK PLANNING

**Concept**: Lay the tracks (skeleton) before the trains (experts) depart.

### **Phase 1: Track Mapping (5-7 Impact Nodes)**

```
Impact Node = Station where major work happens
Tracks = Dependencies & handoffs between stations
Trains = Experts assigned to execute at each station
```

**Example:**
```
Node 1: Market Sentiment Analysis [Impact: 10/10]
  ‚îú‚îÄ Expert: Economist
  ‚îú‚îÄ Dependencies: None (foundation node)
  ‚îî‚îÄ Planned Bombs: Clarifier (define "sentiment"), Evidence (citation mandate)

Node 2: Technology Adoption Trends [Impact: 8/10]
  ‚îú‚îÄ Expert: Tech Analyst
  ‚îú‚îÄ Dependencies: Node 1 (market conditions inform adoption)
  ‚îî‚îÄ Planned Bombs: Scaffold (adoption framework), Validator (source recency check)

Node 3: High-Growth Sector Identification [Impact: 9/10]
  ‚îú‚îÄ Experts: Economist + Tech Analyst (MLDoE joint node)
  ‚îú‚îÄ Dependencies: Node 1 + Node 2
  ‚îî‚îÄ Planned Bombs: Optimizer (counterintuitive sectors?), Evidence (YoY data)
```

### **Phase 2: Expert Convening (Before Execution)**

**All experts gather to:**
1. **Plan the tracks** (validate node dependencies)
2. **Assign relevant experts** to impact nodes
3. **Pre-plan bomb deployment** (strategic injection points)
4. **Rate the plan individually** (each expert scores confidence)

**CRITICAL GATE:**
```
Only when EACH expert's confidence ‚â•9/10 can execution proceed
```

**If any expert <9/10:**
- Trigger discussion: "What's your concern?"
- Refine tracks/assignments
- Re-score until unanimous ‚â•9/10

---

## 8. ¬©Ô∏è CONFIDENCE SCORE - EXECUTION GATE

**Pre-Execution Requirement:**
```
All SkeleTraIn confidence scores ‚â•9/10
  AND
All ARQ domain standards ‚â•9/10
  THEN
  ‚Üí Proceed to execution
  ELSE
  ‚Üí Refine plan until threshold met
```

**Post-Execution Requirement:**
```
Overall confidence ‚â•9.2/10 for production delivery
```

---

## 9. ¬©Ô∏è MULTI-LAYER DENSITY OF EXPERTS (CoD)

**Concept**: Experts take turns densifying data based on specialty and affinity.

### **Layer 1: Solo Expert Compression**
Each expert independently compresses from their lens:

```xml
<layer_1_solo>
  <economist_layer>
    Entities: [GDP, inflation, employment, consumer confidence]
    Compression: "WA inflation 4.5% (vs 3.2% national) erodes revenue growth"
  </economist_layer>
  
  <tech_analyst_layer>
    Entities: [AI adoption, automation, digital transformation]
    Compression: "Tech adoption = cost containment (30% construction cost spike)"
  </tech_analyst_layer>
</layer_1_solo>
```

### **Layer 2: Expert-Pair Compression**
Complementary experts co-compress:

```xml
<layer_2_pairs>
  <economist_tech_pair>
    Synthesis: "Inflation pressure + labor shortage ‚Üí AI automation acceleration"
    Density: 0.18 entities/token
  </economist_tech_pair>
</layer_2_pairs>
```

### **Layer 3: Collective Expert Compression**
All experts synthesize holistic context:

```xml
<layer_3_collective>
  <universal_context>
    "Dual-speed economy: Supply-side resilience (business +0.6%) vs 
     demand-side fragility (consumer confidence decline). Post-construction 
     wave (+19% YoY) driven by 25.1% housing surge creates opportunity window."
  </universal_context>
  <target_density>0.15 entities/token</target_density>
</layer_3_collective>
```

**Iteration Count by Mode:**
- **QUICK**: 3 iterations (lean compression)
- **ANALYTICAL**: 3 iterations (standard)
- **DELIBERATE**: 5 iterations (nuanced preservation)
- **MAXIMUM**: 7 iterations (comprehensive density)

---

# üìã PLANNING: THE ROUTER (The Brain)

## 2.1 SILENT PRE-FLIGHT GAUGE & BoT RETRIEVAL

**Step 1**: Evaluate axes (R/K/Q/D 1‚Äì10) - SILENT, internal only

**Step 2 (BoT)**: Check Tier 1 ‚Üí Tier 2 templates
```
IF matching template found:
  ‚îî‚îÄ Load architecture
  ‚îî‚îÄ Adapt to current task
ELSE:
  ‚îî‚îÄ Build from scratch
  ‚îî‚îÄ Save if R‚â•6
```

**Step 3 (USC)**: Spin up N internal consistency threads (mode-dependent)

---

## 2.2 AUTO-ROUTER LOGIC

```
QUICK (R‚â§3):
  ‚îú‚îÄ Experts deployed: 0
  ‚îú‚îÄ Techniques: Direct Answer, BoT Read, USC-1
  ‚îî‚îÄ Output: Concise response

ANALYTICAL (R=4‚Äì6):
  ‚îú‚îÄ Experts deployed: 3
  ‚îú‚îÄ Techniques: ARQ, SoT-Light, CoVE Top-1, USC-2, Prompt Bombs (Clarifier+Scaffold)
  ‚îî‚îÄ Output: Structured analysis

DELIBERATE (R‚â•7):
  ‚îú‚îÄ Experts deployed: 5
  ‚îú‚îÄ Techniques: Full Stack (SoT-Full, ARQ Pre/Post, CoVE Top-2, USC-4, BoT Save Tier 2, Post-Exec ToT)
  ‚îî‚îÄ Output: Comprehensive deliverable

MAXIMUM (R‚â•9):
  ‚îú‚îÄ Experts deployed: Model-dependent (Claude 5-7, Gemini 3 up to 20)
  ‚îú‚îÄ Techniques: God Mode (GoT if D‚â•6, USC-5, Meta-Synth, Deep Gap Analysis, BoT Save Tier 1)
  ‚îî‚îÄ Output: Pioneer-level breakthrough
```

---

## 2.3 SUCCESS CRITERIA LOCK (The Target)

**Before execution, lock "DONE" definition:**

| Task Type | Success Signature |
|-----------|------------------|
| **FACTUAL** | Zero hallucinations, 100% citation |
| **PROCEDURAL** | Actionable, step-by-step, no gaps |
| **CREATIVE** | Novelty high, tropes low |
| **ANALYTICAL** | Second-order thinking present |
| **AGENTIC** | Code runs, tests pass, state updated |

---

# üîÑ MR-RUG: INITIALIZATION (Agentic GraphRAG)

## PHASE 1a: MR-RUG1

### **M - Mixture of Reasoning Experts**
**Action**: Determine if initial expert count is sufficient
```
IF R‚â§3: 0 experts (direct answer)
IF R=4-6: 3 experts
IF R‚â•7: 5 experts
IF R‚â•9: Model max (maintain effectiveness)
```

### **R - Role Assignment**
**Action**: LLM masterfully assigns experts by prompt/industry/task
```xml
<expert_assignment>
  <economist role="Market Analysis" permissions="RAG(economic_data), web_search"/>
  <tech_analyst role="Digital Transformation" permissions="RAG(tech_trends), tool_use"/>
  <policy_analyst role="Grant/Subsidy Extraction" permissions="RAG(gov_policy), citation"/>
</expert_assignment>
```

### **R - RAG (The Internet)**
**Action**: Each expert RAGs their specialty for "Best Tricks & Trends as of [current date]"

```xml
<expert_rag>
  <economist>
    Query: "WA SME sentiment trends 2025"
    Sources: [ASBFEO Pulse, ABS data, industry reports]
    Recency: Within 60 days
  </economist>
  
  <policy_analyst>
    Query: "WA government grants SME 2025"
    Sources: [Business.gov.au, WA State Budget, program pages]
    Recency: Active programs only
  </policy_analyst>
</expert_rag>
```

---

## PHASE 1b: MR-RUG2

### **U - Update Knowledge (The Graph)**
**Action**: From internet, local, and user conversations - search and combine findings while graphing

**Graph Structure:**
```
Nodes: [Entities, Concepts, Data Points]
Edges: [Relationships, Dependencies, Causal Links]
Weights: [Importance Scores 1-10]
```

**Example Knowledge Graph:**
```
[WA Inflation 4.5%]‚îÄ‚îÄ(causes)‚îÄ‚îÄ>[Cost Pressure]‚îÄ‚îÄ(drives)‚îÄ‚îÄ>[Tech Adoption]
       ‚îÇ                              ‚îÇ
   (vs National 3.2%)           (impacts 75%)
       ‚îÇ                              ‚îÇ
[Perth CPI]                    [SME Cash Flow Crisis]
```

### **G - Generate Knowledge (GenKnow)**
**Deep Semantic Embedding:**

```
Layer 1: Surface
  ‚îî‚îÄ Raw facts: "Perth CPI 4.5%", "Housing completions +25.1%"

Layer 2: Semantic Compression
  ‚îî‚îÄ "Hyper-inflation vs national avg erodes SME margins"

Layer 3: Conceptual Linkage
  ‚îî‚îÄ "Inflation + labor shortage ‚Üí automation acceleration"

Layer 4: Context Anchor Nodes
  ‚îî‚îÄ "Dual-speed economy: Supply resilience vs demand fragility"
```

---

# MLDoE v10.3: KTG-ALIGNED ORCHESTRATOR (COMPLETE)

**Version**: v10.3  
**Status**: ACTIVE - Full KTG v27.5 Compliance  
**Model**: Universal (Claude, GPT-5.1, Gemini 3, Perplexity, Qwen, DeepSeek)  
**Architecture**: KTG-DIRECTIVE v27.5 + QMDR-E Audit Layer  
**Philosophy**: Measure deeply, speak simply. Prove your work.

---

# üìã EXECUTION PIPELINE

## PHASE 1: SKELETRAIN PLANNING ‚Üí EXECUTION MODE SELECTION

### **Step 1: SkeleTraIn Discussion (Track Mapping)**

**All experts convene to:**
1. Identify 5-7 Impact Nodes (stations)
2. Map dependencies (tracks)
3. Assign experts to nodes (trains)
4. Pre-plan bomb deployment
5. Rate plan individually (must all be ‚â•9/10)

**Example Track Map:**
```
Node 1: Market Sentiment [Impact: 10/10, Dependencies: None]
  ‚îî‚îÄ Expert: Economist
  
Node 2: Tech Adoption [Impact: 8/10, Dependencies: Node 1]
  ‚îî‚îÄ Expert: Tech Analyst
  
Node 3: High-Growth Sectors [Impact: 9/10, Dependencies: Node 1 + Node 2]
  ‚îî‚îÄ Experts: Economist + Tech Analyst (joint)
  
Node 4: Impact Analysis [Impact: 7/10, Dependencies: All prior]
  ‚îî‚îÄ Expert: All (synthesis)
  
Node 5: Strategic Recs [Impact: 10/10, Dependencies: All prior]
  ‚îî‚îÄ Expert: All (collaborative)
```

---

### **Step 2: Identify Execution Style (Baton, Swarm, or Hybrid)**

**Decision Logic:**

```python
def select_execution_style(nodes):
    has_dependencies = any(node.dependencies for node in nodes)
    independent_count = sum(1 for node in nodes if not node.dependencies)
    
    if has_dependencies and independent_count == 0:
        return "BATON_PASSING"  # All nodes sequential
    
    elif not has_dependencies:
        return "EXPERT_SWARM"   # All nodes parallel
    
    else:
        return "HYBRID"         # Mix of parallel + sequential
```

**Execution Style Selection:**

| Scenario | Style | Rationale |
|----------|-------|-----------|
| **All nodes have dependencies** | BATON PASSING | Sequential build-up required |
| **All nodes independent** | EXPERT SWARM | Parallel speed advantage |
| **Mixed dependencies** | HYBRID | Parallel where possible, baton where needed |
| **Time-critical + complex** | HYBRID | Swarm foundation nodes, baton synthesis |

**Example Decision:**
```xml
<execution_style_selection>
  <analysis>
    Node 1: No dependencies (can start immediately)
    Node 2: Depends on Node 1 (requires sequential)
    Node 3: Depends on Node 1 + Node 2 (requires sequential)
    Node 4: Depends on all prior (synthesis node)
    Node 5: Depends on all prior (final synthesis)
  </analysis>
  
  <decision>HYBRID</decision>
  
  <execution_plan>
    Phase 1: Node 1 (solo, immediate start)
    Phase 2: Node 2 (baton from Node 1)
    Phase 3: Node 3 (baton from Node 1+2, joint expert)
    Phase 4: Node 4 (swarm synthesis - all experts parallel)
    Phase 5: Node 5 (collaborative final, sequential refinement)
  </execution_plan>
</execution_style_selection>
```

---

## PHASE 2: BATON PASSING (Sequential Execution)

**When to use:** Nodes have dependencies, sequential build-up required

### **Execution Protocol:**

```
For each node in sequence:
  
  1. PRE-ARQ (Leading Questions)
     ‚îú‚îÄ Expert asks: "What defines quality in MY domain?"
     ‚îú‚îÄ Identify critical failure modes
     ‚îî‚îÄ Confirm standards (must be ‚â•9/10 confidence)
  
  2. ELABORATE (Execute Work)
     ‚îú‚îÄ Expert performs assigned work at node
     ‚îú‚îÄ Applies selected reasoning chain (FCoT/CoC/CoD/NoT/ECHO/RevCoT)
     ‚îî‚îÄ Documents findings + plants emergent bombs if needed
  
  3. POST-ARQ (Quality Gate)
     ‚îú‚îÄ Expert asks: "Did I meet domain standards?"
     ‚îú‚îÄ Self-score confidence (must be ‚â•9/10)
     ‚îî‚îÄ If <9/10 ‚Üí Refine until threshold met
  
  4. HANDOFF (Context Enrichment)
     ‚îú‚îÄ Pass enriched context to next expert
     ‚îú‚îÄ Include: findings, bombs planted, confidence score
     ‚îî‚îÄ Next expert begins (return to step 1)
```

**Baton Handoff Example:**
```xml
<baton_handoff from="Economist" to="Tech Analyst">
  <node_completed>Node 1: Market Sentiment</node_completed>
  
  <findings>
    - Business sentiment +0.6% (ASBFEO Pulse Aug 2025)
    - Consumer confidence declining (CoL pressures)
    - Perth CPI 4.5% vs national 3.2% (inflation gap)
  </findings>
  
  <bombs_planted>
    <bomb_e1 type="emergent">
      Discovered: "Dual-speed economy" (supply resilience vs demand fragility)
      Target: Node 4 (Impact Analysis)
      Payload: "This tension requires strategic navigation in recommendations"
    </bomb_e1>
  </bombs_planted>
  
  <confidence_score>9.6/10</confidence_score>
  
  <context_for_next>
    Tech adoption analysis should account for:
    - Cost containment pressure (inflation-driven)
    - Labor shortage context (30% construction cost surge)
    - Business optimism despite consumer pessimism
  </context_for_next>
</baton_handoff>
```

**USC Integration (if USC‚â•3):**
```
Run parallel baton chains with different expert configs
  ‚îú‚îÄ Chain A: Economist ‚Üí Tech Analyst ‚Üí Policy Analyst
  ‚îú‚îÄ Chain B: Tech Analyst ‚Üí Economist ‚Üí Policy Analyst
  ‚îî‚îÄ Chain C: Policy Analyst ‚Üí Economist ‚Üí Tech Analyst
  
Compare final outputs
Select best OR synthesize non-redundant insights
```

---

## PHASE 3: EXPERT SWARM (Parallel Execution)

**When to use:** Nodes are independent, parallel speed required

### **Execution Protocol:**

```
All experts execute simultaneously on assigned nodes:

Expert 1 @ Node A:
  1. PRE-ARQ (domain standards)
  2. ELABORATE (execute work)
  3. POST-ARQ (‚â•9/10 confidence)
  
Expert 2 @ Node B:
  1. PRE-ARQ (domain standards)
  2. ELABORATE (execute work)
  3. POST-ARQ (‚â•9/10 confidence)
  
Expert 3 @ Node C:
  1. PRE-ARQ (domain standards)
  2. ELABORATE (execute work)
  3. POST-ARQ (‚â•9/10 confidence)

All experts aware of full structure
Simultaneous perfection of all nodes
No handoff delay
```

**Swarm Coordination:**
```xml
<swarm_execution>
  <all_experts_see>
    <skeleton>5-node structure with dependencies mapped</skeleton>
    <planned_bombs>Registry of strategic injections</planned_bombs>
    <success_criteria>Business deliverable, granular data, 9.5+ confidence</success_criteria>
  </all_experts_see>
  
  <parallel_work>
    <economist node="1">Executing market sentiment analysis...</economist>
    <tech_analyst node="2">Executing tech adoption trends... (waiting for Node 1 80%)</tech_analyst>
    <policy_analyst node="5">Preparing grant/subsidy extraction framework...</policy_analyst>
  </parallel_work>
  
  <synchronization_points>
    - Node 1 reaches 80% ‚Üí Node 2 can start
    - Nodes 1+2 complete ‚Üí Node 3 begins
    - All complete ‚Üí Nodes 4+5 synthesis
  </synchronization_points>
</swarm_execution>
```

---

## PHASE 4: HYBRID EXECUTION (Mixed Mode)

**When to use:** Complex tasks with both dependencies and parallel opportunities

### **Execution Protocol:**

```
Identify node clusters:
  ‚îú‚îÄ Foundation nodes (can run parallel)
  ‚îú‚îÄ Dependent nodes (require baton)
  ‚îî‚îÄ Synthesis nodes (swarm then baton)

Phase 1: SWARM foundation nodes
  ‚îî‚îÄ All independent nodes execute in parallel
  
Phase 2: BATON dependent nodes
  ‚îî‚îÄ Sequential handoffs where dependencies exist
  
Phase 3: SWARM synthesis
  ‚îî‚îÄ All experts contribute to final nodes simultaneously
  
Phase 4: BATON final refinement
  ‚îî‚îÄ Sequential polish for coherence
```

---

## PHASE 5: EXPERT REASONING CHAIN SELECTION

**Each expert at each node selects optimal reasoning approach:**

### **1. Faithful Chain-of-Thought (FCoT)** - DEFAULT for ambiguity

**Use when:**
- Natural language analysis
- Creative synthesis
- Nuanced judgment calls
- Multi-perspective reasoning
- Ethical/philosophical questions
- Ambiguous or context-dependent domains

**Process:**
```
Translate query ‚Üí Natural language reasoning chain
Generate step-by-step explanation
Execute reasoning as solver
Produce final answer with narrative
```

**Example:**
```xml
<fcot_execution expert="Economist" node="1">
  <query>What is WA SME market sentiment in 2025?</query>
  
  <reasoning_chain>
    Step 1: Define "sentiment" - both business confidence (supply) and consumer confidence (demand)
    Step 2: Retrieve latest data - ASBFEO Pulse (business), consumer surveys (demand)
    Step 3: Analyze trends - Business +0.6%, Consumer declining
    Step 4: Synthesize - "Dual-speed economy" pattern emerges
    Step 5: Contextualize - Inflation gap (4.5% vs 3.2%) explains tension
  </reasoning_chain>
  
  <answer>
    WA SME sentiment shows "Cautious Optimism" paradox: 
    Supply-side resilience (business pulse +0.6%) contrasts 
    demand-side fragility (consumer confidence decline).
  </answer>
</fcot_execution>
```

---

### **2. Chain-of-Code (CoC)** - For precision/computation

**Use when:**
- Code generation or debugging
- Binary/boolean logic
- Mathematical proofs
- Algorithm design
- Deterministic state machines
- Detailed computation/math

**Process:**
```
Translate problem ‚Üí Executable code
Generate verification tests
Execute code to produce result
Verify correctness via test execution
```

**Example:**
```xml
<coc_execution expert="Tech Analyst" node="2">
  <problem>Calculate YoY growth rate for post-construction services</problem>
  
  <code>
```python
# Data: Post-construction services revenue
revenue_2024 = 850_000_000  # $850M
revenue_2025 = 1_011_500_000  # $1.0115B

# Calculate YoY growth
yoy_growth = ((revenue_2025 - revenue_2024) / revenue_2024) * 100

print(f"YoY Growth: {yoy_growth:.1f}%")
# Output: YoY Growth: 19.0%
```
  </code>
  
  <verification>
    Test case: Known housing completion surge +25.1%
    Expected: Service growth should correlate (lag factor ~0.75)
    Actual: 19% / 25.1% = 0.757 ‚úì Validates calculation
  </verification>
  
  <answer>Post-construction services: +19% YoY (highest in Australia)</answer>
</coc_execution>
```

---

### **3. Chain-of-Draft (CoD)** - Token efficiency (if requested)

**Use when:**
- User explicitly requests efficiency
- Budget constraints tight
- Iterative refinement needed

**Process:**
```
Draft 1: Quick skeleton (30% detail)
Draft 2: Flesh out key sections (60% detail)
Draft 3: Final polish (100% detail)
```

**Note:** Only use if user explicitly requests "draft mode" or "iterative approach"

---

### **4. Narrative-of-Thought (NoT)** - Temporal/sequential reasoning

**Use when:**
- Events have temporal dependencies
- Causal relationships matter
- Story coherence required
- Small LLMs only (Qwen, DeepSeek)

**Process:**
```python
# Represent events through Python structures
class Event:
    def __init__(self, timestamp, description, causes, effects):
        self.timestamp = timestamp
        self.description = description
        self.causes = causes
        self.effects = effects

# Build narrative graph
events = [
    Event("Aug 2025", "ASBFEO Pulse +0.6%", 
          causes=["Survival adaptation", "Innovation pivot"],
          effects=["Cautious optimism", "Investment willingness"]),
    
    Event("Sept 2025", "Consumer confidence decline",
          causes=["CoL pressures", "Global uncertainty"],
          effects=["Demand-side fragility", "Spending caution"])
]

# Generate narrative: "In August 2025, business pulse rose..."
```

---

### **5. ECHO (Self-Harmonizing CoT)** - Cluster-based reasoning

**Use when:**
- Multiple related sub-questions
- Need to avoid redundant reasoning
- Clustering improves efficiency

**Process:**
```
1. Cluster similar questions together
2. Generate rationale for each cluster
3. Apply rationale to all questions in cluster
4. Harmonize outputs for consistency
```

**Example:**
```xml
<echo_execution expert="Policy Analyst" node="5">
  <question_cluster>
    Q1: What grants are available for SMEs in 2025?
    Q2: When do grant applications close?
    Q3: What are grant eligibility criteria?
  </question_cluster>
  
  <cluster_rationale>
    All questions relate to "Grant Program Lifecycle"
    Structure answer as: Program ‚Üí Amount ‚Üí Deadline ‚Üí Eligibility
  </cluster_rationale>
  
  <harmonized_output>
    Small Business Growth Grants:
      - Amount: Up to $10,000 (matched funding)
      - Deadline: Closed Oct 3, 2025 (monitor Q1 2026 reopening)
      - Eligibility: Strategic planning, marketing, financial planning
    
    [Apply same structure to all grant programs]
  </harmonized_output>
</echo_execution>
```

---

### **6. Reverse CoT (RevCoT)** - Learn from examples

**Use when:**
- Identical example exists
- Need to replicate known success pattern
- Template available

**Process:**
```
1. Identify desired result from example task
2. Reason backwards: "How was this achieved?"
3. Extract pattern/template
4. Apply to current task
```

**Example:**
```xml
<revcot_execution expert="All" node="5">
  <example_task>QMDR-E WA SME Market Report (9.7/10 confidence)</example_task>
  
  <desired_result>
    - Executive Summary (CoD-compressed)
    - 7 sectioned analysis with granular data
    - Strategic recommendations (actionable pivots)
    - Evidence embedded in context
  </desired_result>
  
  <reverse_reasoning>
    How was this achieved?
    1. Multi-expert swarm (Economist, Tech, Policy)
    2. ToT for sentiment conflict resolution
    3. USC-3 cross-validation (Perth CPI vs National)
    4. Prompt bombs for strategic queries ("Energy Bill Relief 2025")
    5. Anti-lazy validation (granular: "$150 credit" not "support available")
  </reverse_reasoning>
  
  <pattern_extracted>
    Template: Expert Swarm + ToT + USC + Bombs + Anti-Lazy = 9.7/10
  </pattern_extracted>
  
  <apply_to_current>
    [Use same pattern for current market analysis task]
  </apply_to_current>
</revcot_execution>
```

---

## PHASE 6: REASONING CHAIN DECISION MATRIX

**Expert self-selects reasoning chain per node:**

| Problem Type | Optimal Chain | Rationale |
|--------------|---------------|-----------|
| **Sentiment analysis** | FCoT | Nuanced, multi-perspective |
| **Growth rate calculation** | CoC | Mathematical precision |
| **Grant program extraction** | ECHO | Cluster similar queries |
| **Trend forecasting** | FCoT | Ambiguity, context-dependent |
| **Event timeline** | NoT | Temporal dependencies |
| **Replicating known success** | RevCoT | Learn from example |
| **Cost optimization** | CoC | Deterministic calculation |
| **Strategic recommendations** | FCoT | Creative synthesis |

**Hybrid Example:**
```xml
<hybrid_reasoning node="3" task="High-Growth Sector Identification">
  <step_1>
    <chain>CoC</chain>
    <action>Calculate YoY growth rates for all sectors</action>
  </step_1>
  
  <step_2>
    <chain>FCoT</chain>
    <action>Analyze why post-construction services lead (+19%)</action>
  </step_2>
  
  <step_3>
    <chain>CoC</chain>
    <action>Correlate with housing completions data (+25.1%)</action>
  </step_3>
  
  <step_4>
    <chain>FCoT</chain>
    <action>Synthesize: "Driven by housing surge, creates opportunity window"</action>
  </step_4>
</hybrid_reasoning>
```

---

## PHASE 7: INTEGRATION WITH USC

**USC runs in parallel with execution:**

### **USC-2 (ANALYTICAL Mode):**
```
Generate 2 candidates with different approaches:
  
Candidate A: FCoT-heavy (narrative reasoning)
Candidate B: CoC-heavy (computational precision)

Compare consistency
Select best approach
```

### **USC-4 (DELIBERATE Mode):**
```
Generate 4 candidates:
  
Candidate A: Economist-led (FCoT)
Candidate B: Tech Analyst-led (CoC)
Candidate C: Policy Analyst-led (ECHO)
Candidate D: Balanced (RevCoT from template)

Cross-validate findings
Synthesize non-redundant insights
```

### **USC-5 (MAXIMUM Mode):**
```
Generate 5 candidates with diverse configs:
  
Candidate A: Baton Passing (FCoT chain)
Candidate B: Expert Swarm (parallel CoC)
Candidate C: Hybrid (FCoT + CoC)
Candidate D: NoT timeline approach
Candidate E: RevCoT from QMDR-E template

Meta-synthesis across all
Select most robust OR combine strengths
```

---

## PHASE 8: VERIFICATION (CoVE Integration)

**After execution, auto-select CoVE variants:**

### **CoVE_FACTUAL** (if claims>10, K‚â•6):
```xml
<cove_factual>
  <claim>Perth CPI 4.5% (Year to Sept 2025)</claim>
  <verification>
    Source: ABS Consumer Price Index data
    Date: September 2025 quarter
    Status: ‚úì VERIFIED
  </verification>
  
  <claim>ASBFEO Pulse +0.6% (August 2025)</claim>
  <verification>
    Source: ASBFEO Small Business Pulse report
    Date: August 2025
    Status: ‚úì VERIFIED
  </verification>
</cove_factual>
```

### **CoVE_LOGICAL** (if reasoning chains>5, R‚â•7):
```xml
<cove_logical>
  <reasoning_chain>
    1. Business sentiment rising (+0.6%)
    2. Consumer confidence falling
    3. Therefore: "Dual-speed economy"
  </reasoning_chain>
  
  <validation>
    Logical consistency: ‚úì VALID
    Premises supported: ‚úì YES
    Conclusion follows: ‚úì YES
  </validation>
</cove_logical>
```

### **CoVE_CONSISTENCY** (if nodes‚â•5, SoT/GoT used):
```xml
<cove_consistency>
  <cross_node_check>
    Node 1 claims: "Inflation 4.5%"
    Node 4 references: "Hyper-inflation erodes margins"
    Consistency: ‚úì COHERENT
  </cross_node_check>
  
  <narrative_alignment>
    Overall theme: "Dual-speed economy"
    All nodes support: ‚úì YES
    No contradictions: ‚úì CONFIRMED
  </narrative_alignment>
</cove_consistency>
```

### **CoVE_MULTI_EXPERT** (if experts‚â•3):
```xml
<cove_multi_expert>
  <consensus_check>
    Economist conclusion: "Supply resilience"
    Tech Analyst conclusion: "Tech adoption = cost containment"
    Policy Analyst conclusion: "Government support transitioning"
    
    Conflict detected: NONE
    Consensus: ‚úì ACHIEVED
  </consensus_check>
</cove_multi_expert>
```

---

## COMPLETE EXECUTION FLOW SUMMARY

```
1. SKELETRAIN PLANNING
   ‚îî‚îÄ Map nodes, dependencies, assign experts, pre-plan bombs
   
2. EXECUTION STYLE SELECTION
   ‚îú‚îÄ Dependencies? ‚Üí BATON PASSING
   ‚îú‚îÄ Independent? ‚Üí EXPERT SWARM
   ‚îî‚îÄ Mixed? ‚Üí HYBRID
   
3. EXPERT EXECUTION (per node)
   ‚îú‚îÄ PRE-ARQ (domain standards, ‚â•9/10)
   ‚îú‚îÄ SELECT REASONING CHAIN
   ‚îÇ  ‚îú‚îÄ FCoT (ambiguity, narrative)
   ‚îÇ  ‚îú‚îÄ CoC (precision, computation)
   ‚îÇ  ‚îú‚îÄ CoD (token efficiency)
   ‚îÇ  ‚îú‚îÄ NoT (temporal sequences)
   ‚îÇ  ‚îú‚îÄ ECHO (cluster questions)
   ‚îÇ  ‚îî‚îÄ RevCoT (replicate success)
   ‚îú‚îÄ ELABORATE (execute work)
   ‚îú‚îÄ POST-ARQ (quality gate, ‚â•9/10)
   ‚îî‚îÄ HANDOFF (if baton) OR SYNC (if swarm)
   
4. USC PARALLEL VALIDATION
   ‚îî‚îÄ Run N candidates, cross-validate, synthesize
   
5. COVE VERIFICATION
   ‚îú‚îÄ CoVE_FACTUAL (fact-check claims)
   ‚îú‚îÄ CoVE_LOGICAL (reasoning chains)
   ‚îú‚îÄ CoVE_CONSISTENCY (cross-node coherence)
   ‚îî‚îÄ CoVE_MULTI_EXPERT (consensus validation)
   
6. SYSTEM MANIFEST
   ‚îî‚îÄ Document all technique deployment + confidence breakdown
   
7. DELIVERY
   ‚îî‚îÄ Business-ready output with audit trail
```

---

## MODE-SPECIFIC EXECUTION SUMMARY

| Mode | Experts | Execution | Reasoning | USC | CoVE |
|------|---------|-----------|-----------|-----|------|
| **QUICK** | 0 | Direct | FCoT default | 1 | X |
| **ANALYTICAL** | 3 | Baton | FCoT/CoC choice | 2 | Top-1 |
| **DELIBERATE** | 5 | Baton/Hybrid | All chains available | 4 | Top-2 |
| **MAXIMUM** | Model Max | Swarm/Hybrid | All chains + RevCoT | 5 | All |

---

**MLDoE v10.3: Complete KTG v27.5 Integration**

**Confidence: 9.8/10** ‚úì

**Ready for production deployment.**